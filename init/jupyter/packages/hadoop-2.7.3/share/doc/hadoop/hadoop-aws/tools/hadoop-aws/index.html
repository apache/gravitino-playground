<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!-- Generated by Apache Maven Doxia at 2016-08-18 -->
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>Apache Hadoop Amazon Web Services support &#x2013; Hadoop-AWS module: Integration with Amazon Web Services</title>
    <style type="text/css" media="all">
      @import url("../../css/maven-base.css");
      @import url("../../css/maven-theme.css");
      @import url("../../css/site.css");
    </style>
    <link rel="stylesheet" href="../../css/print.css" type="text/css" media="print" />
        <meta name="Date-Revision-yyyymmdd" content="20160818" />
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
      </head>
  <body class="composite">
    <div id="banner">
                  <a href="http://hadoop.apache.org/" id="bannerLeft">
                                        <img src="http://hadoop.apache.org/images/hadoop-logo.jpg" alt="" />
                </a>
                        <a href="http://www.apache.org/" id="bannerRight">
                                        <img src="http://www.apache.org/images/asf_logo_wide.png" alt="" />
                </a>
            <div class="clear">
        <hr/>
      </div>
    </div>
    <div id="breadcrumbs">
            
                                <div class="xleft">
                          <a href="http://www.apache.org/" class="externalLink">Apache</a>
                &gt;
                      <a href="http://hadoop.apache.org/" class="externalLink">Hadoop</a>
                &gt;
                      <a href="../../">Apache Hadoop Amazon Web Services support</a>
                  </div>
            <div class="xright">            <a href="http://wiki.apache.org/hadoop" class="externalLink">Wiki</a>
            |
                <a href="https://git-wip-us.apache.org/repos/asf/hadoop.git" class="externalLink">git</a>
              
                                &nbsp;| Last Published: 2016-08-18
              &nbsp;| Version: 2.7.3
            </div>
      <div class="clear">
        <hr/>
      </div>
    </div>
    <div id="leftColumn">
      <div id="navcolumn">
             
                                                <h5>General</h5>
                  <ul>
                  <li class="none">
                  <a href="../../../index.html">Overview</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/SingleCluster.html">Single Node Setup</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/ClusterSetup.html">Cluster Setup</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/CommandsManual.html">Hadoop Commands Reference</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/FileSystemShell.html">FileSystem Shell</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/Compatibility.html">Hadoop Compatibility</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/InterfaceClassification.html">Interface Classification</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/filesystem/index.html">FileSystem Specification</a>
            </li>
          </ul>
                       <h5>Common</h5>
                  <ul>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/CLIMiniCluster.html">CLI Mini Cluster</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/NativeLibraries.html">Native Libraries</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/Superusers.html">Proxy User</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/RackAwareness.html">Rack Awareness</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/SecureMode.html">Secure Mode</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/ServiceLevelAuth.html">Service Level Authorization</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/HttpAuthentication.html">HTTP Authentication</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-kms/index.html">Hadoop KMS</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/Tracing.html">Tracing</a>
            </li>
          </ul>
                       <h5>HDFS</h5>
                  <ul>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html">HDFS User Guide</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/HDFSCommands.html">HDFS Commands Reference</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html">High Availability With QJM</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithNFS.html">High Availability With NFS</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/Federation.html">Federation</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/ViewFs.html">ViewFs Guide</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/HdfsSnapshots.html">HDFS Snapshots</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/HdfsDesign.html">HDFS Architecture</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/HdfsEditsViewer.html">Edits Viewer</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/HdfsImageViewer.html">Image Viewer</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/HdfsPermissionsGuide.html">Permissions and HDFS</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/HdfsQuotaAdminGuide.html">Quotas and HDFS</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/Hftp.html">HFTP</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/LibHdfs.html">C API libhdfs</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/WebHDFS.html">WebHDFS REST API</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-hdfs-httpfs/index.html">HttpFS Gateway</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/ShortCircuitLocalReads.html">Short Circuit Local Reads</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/CentralizedCacheManagement.html">Centralized Cache Management</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/HdfsNfsGateway.html">HDFS NFS Gateway</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/HdfsRollingUpgrade.html">HDFS Rolling Upgrade</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/ExtendedAttributes.html">Extended Attributes</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/TransparentEncryption.html">Transparent Encryption</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/HdfsMultihoming.html">HDFS Support for Multihoming</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/ArchivalStorage.html">Archival Storage, SSD & Memory</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/MemoryStorage.html">Memory Storage Support</a>
            </li>
          </ul>
                       <h5>MapReduce</h5>
                  <ul>
                  <li class="none">
                  <a href="../../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html">MapReduce Tutorial</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapredCommands.html">MapReduce Commands Reference</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduce_Compatibility_Hadoop1_Hadoop2.html">Compatibilty between Hadoop 1.x and Hadoop 2.x</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/EncryptedShuffle.html">Encrypted Shuffle</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/PluggableShuffleAndPluggableSort.html">Pluggable Shuffle/Sort</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/DistributedCacheDeploy.html">Distributed Cache Deploy</a>
            </li>
          </ul>
                       <h5>MapReduce REST APIs</h5>
                  <ul>
                  <li class="none">
                  <a href="../../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapredAppMasterRest.html">MR Application Master</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-mapreduce-client/hadoop-mapreduce-client-hs/HistoryServerRest.html">MR History Server</a>
            </li>
          </ul>
                       <h5>YARN</h5>
                  <ul>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/index.html">Overview</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/YARN.html">YARN Architecture</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/CapacityScheduler.html">Capacity Scheduler</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/FairScheduler.html">Fair Scheduler</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/ResourceManagerRestart.html">ResourceManager Restart</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/ResourceManagerHA.html">ResourceManager HA</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/NodeLabel.html">Node Labels</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/WebApplicationProxy.html">Web Application Proxy</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/TimelineServer.html">YARN Timeline Server</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/WritingYarnApplications.html">Writing YARN Applications</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/YarnCommands.html">YARN Commands</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/NodeManagerRestart.html">NodeManager Restart</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/YarnApplicationSecurity.html">YARN Application Security</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/DockerContainerExecutor.html">DockerContainerExecutor</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/NodeManagerCgroups.html">Using CGroups</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/SecureContainer.html">Secure Containers</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/registry/index.html">Registry</a>
            </li>
          </ul>
                       <h5>YARN REST APIs</h5>
                  <ul>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/WebServicesIntro.html">Introduction</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/ResourceManagerRest.html">Resource Manager</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/NodeManagerRest.html">Node Manager</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/TimelineServer.html#Timeline_Server_REST_API_v1">Timeline Server</a>
            </li>
          </ul>
                       <h5>Hadoop Compatible File Systems</h5>
                  <ul>
                  <li class="none">
                  <a href="../../../hadoop-aws/tools/hadoop-aws/index.html">Amazon S3</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-azure/index.html">Azure Blob Storage</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-openstack/index.html">OpenStack Swift</a>
            </li>
          </ul>
                       <h5>Auth</h5>
                  <ul>
                  <li class="none">
                  <a href="../../../hadoop-auth/index.html">Overview</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-auth/Examples.html">Examples</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-auth/Configuration.html">Configuration</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-auth/BuildingIt.html">Building</a>
            </li>
          </ul>
                       <h5>Tools</h5>
                  <ul>
                  <li class="none">
                  <a href="../../../hadoop-streaming/HadoopStreaming.html">Hadoop Streaming</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-archives/HadoopArchives.html">Hadoop Archives</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-distcp/DistCp.html">DistCp</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-gridmix/GridMix.html">GridMix</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-rumen/Rumen.html">Rumen</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-sls/SchedulerLoadSimulator.html">Scheduler Load Simulator</a>
            </li>
          </ul>
                       <h5>Reference</h5>
                  <ul>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/releasenotes.html">Release Notes</a>
            </li>
                  <li class="none">
                  <a href="../../../api/index.html">API docs</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/CHANGES.txt">Common CHANGES.txt</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/CHANGES.txt">HDFS CHANGES.txt</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-mapreduce/CHANGES.txt">MapReduce CHANGES.txt</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-yarn/CHANGES.txt">YARN CHANGES.txt</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/Metrics.html">Metrics</a>
            </li>
          </ul>
                       <h5>Configuration</h5>
                  <ul>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/core-default.xml">core-default.xml</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/hdfs-default.xml">hdfs-default.xml</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml">mapred-default.xml</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-common/yarn-default.xml">yarn-default.xml</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/DeprecatedProperties.html">Deprecated Properties</a>
            </li>
          </ul>
                                 <a href="http://maven.apache.org/" title="Built by Maven" class="poweredBy">
          <img alt="Built by Maven" src="../../images/logos/maven-feather.png"/>
        </a>
                       
                            </div>
    </div>
    <div id="bodyColumn">
      <div id="contentBox">
        <!-- -
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file. --><h1>Hadoop-AWS module: Integration with Amazon Web Services</h1>
<p>The <tt>hadoop-aws</tt> module provides support for AWS integration. The generated JAR file, <tt>hadoop-aws.jar</tt> also declares a transitive dependency on all external artifacts which are needed for this support &#x2014;enabling downstream applications to easily use this support.</p>
<p>Features</p>

<ol style="list-style-type: decimal">
  
<li>The &#x201c;classic&#x201d; <tt>s3:</tt> filesystem for storing objects in Amazon S3 Storage</li>
  
<li>The second-generation, <tt>s3n:</tt> filesystem, making it easy to share data between hadoop and other applications via the S3 object store</li>
  
<li>The third generation, <tt>s3a:</tt> filesystem. Designed to be a switch in replacement for <tt>s3n:</tt>, this filesystem binding supports larger files and promises higher performance.</li>
</ol>
<p>The specifics of using these filesystems are documented below.</p>
<div class="section">
<h2><a name="Warning:_Object_Stores_are_not_filesystems."></a>Warning: Object Stores are not filesystems.</h2>
<p>Amazon S3 is an example of &#x201c;an object store&#x201d;. In order to achieve scalability and especially high availability, S3 has &#x2014;as many other cloud object stores have done&#x2014; relaxed some of the constraints which classic &#x201c;POSIX&#x201d; filesystems promise.</p>
<p>Specifically</p>

<ol style="list-style-type: decimal">
  
<li>Files that are newly created from the Hadoop Filesystem APIs may not be immediately visible.</li>
  
<li>File delete and update operations may not immediately propagate. Old copies of the file may exist for an indeterminate time period.</li>
  
<li>Directory operations: <tt>delete()</tt> and <tt>rename()</tt> are implemented by recursive file-by-file operations. They take time at least proportional to the number of files, during which time partial updates may be visible. If the operations are interrupted, the filesystem is left in an intermediate state.</li>
</ol>
<p>For further discussion on these topics, please consult <a href="../../../hadoop-project-dist/hadoop-common/filesystem/index.html">The Hadoop FileSystem API Definition</a>.</p></div>
<div class="section">
<h2><a name="Warning_2:_your_AWS_credentials_are_valuable"></a>Warning #2: your AWS credentials are valuable</h2>
<p>Your AWS credentials not only pay for services, they offer read and write access to the data. Anyone with the credentials can not only read your datasets &#x2014;they can delete them.</p>
<p>Do not inadvertently share these credentials through means such as 1. Checking in Hadoop configuration files containing the credentials. 1. Logging them to a console, as they invariably end up being seen.</p>
<p>If you do any of these: change your credentials immediately!</p></div>
<div class="section">
<h2><a name="S3"></a>S3</h2>
<div class="section">
<h3><a name="Authentication_properties"></a>Authentication properties</h3>

<div class="source">
<div class="source">
<pre>&lt;property&gt;
  &lt;name&gt;fs.s3.awsAccessKeyId&lt;/name&gt;
  &lt;description&gt;AWS access key ID&lt;/description&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;fs.s3.awsSecretAccessKey&lt;/name&gt;
  &lt;description&gt;AWS secret key&lt;/description&gt;
&lt;/property&gt;
</pre></div></div></div></div>
<div class="section">
<h2><a name="S3N"></a>S3N</h2>
<div class="section">
<h3><a name="Authentication_properties"></a>Authentication properties</h3>

<div class="source">
<div class="source">
<pre>&lt;property&gt;
  &lt;name&gt;fs.s3n.awsAccessKeyId&lt;/name&gt;
  &lt;description&gt;AWS access key ID&lt;/description&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;fs.s3n.awsSecretAccessKey&lt;/name&gt;
  &lt;description&gt;AWS secret key&lt;/description&gt;
&lt;/property&gt;
</pre></div></div></div>
<div class="section">
<h3><a name="Other_properties"></a>Other properties</h3>

<div class="source">
<div class="source">
<pre>&lt;property&gt;
  &lt;name&gt;fs.s3n.block.size&lt;/name&gt;
  &lt;value&gt;67108864&lt;/value&gt;
  &lt;description&gt;Block size to use when reading files using the native S3
  filesystem (s3n: URIs).&lt;/description&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;fs.s3n.multipart.uploads.enabled&lt;/name&gt;
  &lt;value&gt;false&lt;/value&gt;
  &lt;description&gt;Setting this property to true enables multiple uploads to
  native S3 filesystem. When uploading a file, it is split into blocks
  if the size is larger than fs.s3n.multipart.uploads.block.size.
  &lt;/description&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;fs.s3n.multipart.uploads.block.size&lt;/name&gt;
  &lt;value&gt;67108864&lt;/value&gt;
  &lt;description&gt;The block size for multipart uploads to native S3 filesystem.
  Default size is 64MB.
  &lt;/description&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;fs.s3n.multipart.copy.block.size&lt;/name&gt;
  &lt;value&gt;5368709120&lt;/value&gt;
  &lt;description&gt;The block size for multipart copy in native S3 filesystem.
  Default size is 5GB.
  &lt;/description&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;fs.s3n.server-side-encryption-algorithm&lt;/name&gt;
  &lt;value&gt;&lt;/value&gt;
  &lt;description&gt;Specify a server-side encryption algorithm for S3.
  The default is NULL, and the only other currently allowable value is AES256.
  &lt;/description&gt;
&lt;/property&gt;
</pre></div></div></div></div>
<div class="section">
<h2><a name="S3A"></a>S3A</h2>
<div class="section">
<h3><a name="Authentication_properties"></a>Authentication properties</h3>

<div class="source">
<div class="source">
<pre>&lt;property&gt;
  &lt;name&gt;fs.s3a.access.key&lt;/name&gt;
  &lt;description&gt;AWS access key ID. Omit for Role-based authentication.&lt;/description&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;fs.s3a.secret.key&lt;/name&gt;
  &lt;description&gt;AWS secret key. Omit for Role-based authentication.&lt;/description&gt;
&lt;/property&gt;
</pre></div></div></div>
<div class="section">
<h3><a name="Other_properties"></a>Other properties</h3>

<div class="source">
<div class="source">
<pre>&lt;property&gt;
  &lt;name&gt;fs.s3a.connection.maximum&lt;/name&gt;
  &lt;value&gt;15&lt;/value&gt;
  &lt;description&gt;Controls the maximum number of simultaneous connections to S3.&lt;/description&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;fs.s3a.connection.ssl.enabled&lt;/name&gt;
  &lt;value&gt;true&lt;/value&gt;
  &lt;description&gt;Enables or disables SSL connections to S3.&lt;/description&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;fs.s3a.endpoint&lt;/name&gt;
  &lt;description&gt;AWS S3 endpoint to connect to. An up-to-date list is
    provided in the AWS Documentation: regions and endpoints. Without this
    property, the standard region (s3.amazonaws.com) is assumed.
  &lt;/description&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;fs.s3a.proxy.host&lt;/name&gt;
  &lt;description&gt;Hostname of the (optional) proxy server for S3 connections.&lt;/description&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;fs.s3a.proxy.port&lt;/name&gt;
  &lt;description&gt;Proxy server port. If this property is not set
    but fs.s3a.proxy.host is, port 80 or 443 is assumed (consistent with
    the value of fs.s3a.connection.ssl.enabled).&lt;/description&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;fs.s3a.proxy.username&lt;/name&gt;
  &lt;description&gt;Username for authenticating with proxy server.&lt;/description&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;fs.s3a.proxy.password&lt;/name&gt;
  &lt;description&gt;Password for authenticating with proxy server.&lt;/description&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;fs.s3a.proxy.domain&lt;/name&gt;
  &lt;description&gt;Domain for authenticating with proxy server.&lt;/description&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;fs.s3a.proxy.workstation&lt;/name&gt;
  &lt;description&gt;Workstation for authenticating with proxy server.&lt;/description&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;fs.s3a.attempts.maximum&lt;/name&gt;
  &lt;value&gt;10&lt;/value&gt;
  &lt;description&gt;How many times we should retry commands on transient errors.&lt;/description&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;fs.s3a.connection.establish.timeout&lt;/name&gt;
  &lt;value&gt;5000&lt;/value&gt;
  &lt;description&gt;Socket connection setup timeout in milliseconds.&lt;/description&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;fs.s3a.connection.timeout&lt;/name&gt;
  &lt;value&gt;50000&lt;/value&gt;
  &lt;description&gt;Socket connection timeout in milliseconds.&lt;/description&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;fs.s3a.paging.maximum&lt;/name&gt;
  &lt;value&gt;5000&lt;/value&gt;
  &lt;description&gt;How many keys to request from S3 when doing
     directory listings at a time.&lt;/description&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;fs.s3a.threads.max&lt;/name&gt;
  &lt;value&gt;256&lt;/value&gt;
  &lt;description&gt; Maximum number of concurrent active (part)uploads,
  which each use a thread from the threadpool.&lt;/description&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;fs.s3a.threads.core&lt;/name&gt;
  &lt;value&gt;15&lt;/value&gt;
  &lt;description&gt;Number of core threads in the threadpool.&lt;/description&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;fs.s3a.threads.keepalivetime&lt;/name&gt;
  &lt;value&gt;60&lt;/value&gt;
  &lt;description&gt;Number of seconds a thread can be idle before being
    terminated.&lt;/description&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;fs.s3a.max.total.tasks&lt;/name&gt;
  &lt;value&gt;1000&lt;/value&gt;
  &lt;description&gt;Number of (part)uploads allowed to the queue before
  blocking additional uploads.&lt;/description&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;fs.s3a.multipart.size&lt;/name&gt;
  &lt;value&gt;104857600&lt;/value&gt;
  &lt;description&gt;How big (in bytes) to split upload or copy operations up into.&lt;/description&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;fs.s3a.multipart.threshold&lt;/name&gt;
  &lt;value&gt;2147483647&lt;/value&gt;
  &lt;description&gt;Threshold before uploads or copies use parallel multipart operations.&lt;/description&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;fs.s3a.acl.default&lt;/name&gt;
  &lt;description&gt;Set a canned ACL for newly created and copied objects. Value may be private,
     public-read, public-read-write, authenticated-read, log-delivery-write,
     bucket-owner-read, or bucket-owner-full-control.&lt;/description&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;fs.s3a.multipart.purge&lt;/name&gt;
  &lt;value&gt;false&lt;/value&gt;
  &lt;description&gt;True if you want to purge existing multipart uploads that may not have been
     completed/aborted correctly&lt;/description&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;fs.s3a.multipart.purge.age&lt;/name&gt;
  &lt;value&gt;86400&lt;/value&gt;
  &lt;description&gt;Minimum age in seconds of multipart uploads to purge&lt;/description&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;fs.s3a.buffer.dir&lt;/name&gt;
  &lt;value&gt;${hadoop.tmp.dir}/s3a&lt;/value&gt;
  &lt;description&gt;Comma separated list of directories that will be used to buffer file
    uploads to. No effect if fs.s3a.fast.upload is true.&lt;/description&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;fs.s3a.impl&lt;/name&gt;
  &lt;value&gt;org.apache.hadoop.fs.s3a.S3AFileSystem&lt;/value&gt;
  &lt;description&gt;The implementation class of the S3A Filesystem&lt;/description&gt;
&lt;/property&gt;
</pre></div></div></div>
<div class="section">
<h3><a name="S3AFastOutputStream"></a>S3AFastOutputStream</h3>
<p><b>Warning: NEW in hadoop 2.7. UNSTABLE, EXPERIMENTAL: use at own risk</b></p>

<div class="source">
<div class="source">
<pre>&lt;property&gt;
  &lt;name&gt;fs.s3a.fast.upload&lt;/name&gt;
  &lt;value&gt;false&lt;/value&gt;
  &lt;description&gt;Upload directly from memory instead of buffering to
  disk first. Memory usage and parallelism can be controlled as up to
  fs.s3a.multipart.size memory is consumed for each (part)upload actively
  uploading (fs.s3a.threads.max) or queueing (fs.s3a.max.total.tasks)&lt;/description&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;fs.s3a.fast.buffer.size&lt;/name&gt;
  &lt;value&gt;1048576&lt;/value&gt;
  &lt;description&gt;Size (in bytes) of initial memory buffer allocated for an
  upload. No effect if fs.s3a.fast.upload is false.&lt;/description&gt;
&lt;/property&gt;
</pre></div></div>
<p>Writes are buffered in memory instead of to a file on local disk. This removes the throughput bottleneck of the local disk write and read cycle before starting the actual upload. Furthermore, it allows handling files that are larger than the remaining local disk space.</p>
<p>However, non-trivial memory tuning is needed for optimal results and careless settings could cause memory overflow. Up to <tt>fs.s3a.threads.max</tt> parallel (part)uploads are active. Furthermore, up to <tt>fs.s3a.max.total.tasks</tt> additional part(uploads) can be waiting (and thus memory buffers are created). The memory buffer is uploaded as a single upload if it is not larger than <tt>fs.s3a.multipart.threshold</tt>. Else, a multi-part upload is initiatated and parts of size <tt>fs.s3a.multipart.size</tt> are used to protect against overflowing the available memory. These settings should be tuned to the envisioned workflow (some large files, many small ones, &#x2026;) and the physical limitations of the machine and cluster (memory, network bandwidth).</p></div></div>
<div class="section">
<h2><a name="Testing_the_S3_filesystem_clients"></a>Testing the S3 filesystem clients</h2>
<p>Due to eventual consistency, tests may fail without reason. Transient failures, which no longer occur upon rerunning the test, should thus be ignored.</p>
<p>To test the S3* filesystem clients, you need to provide two files which pass in authentication details to the test runner</p>

<ol style="list-style-type: decimal">
  
<li><tt>auth-keys.xml</tt></li>
  
<li><tt>core-site.xml</tt></li>
</ol>
<p>These are both Hadoop XML configuration files, which must be placed into <tt>hadoop-tools/hadoop-aws/src/test/resources</tt>.</p>
<div class="section">
<h3><a name="auth-keys.xml"></a><tt>auth-keys.xml</tt></h3>
<p>The presence of this file triggers the testing of the S3 classes.</p>
<p>Without this file, <i>none of the tests in this module will be executed</i></p>
<p>The XML file must contain all the ID/key information needed to connect each of the filesystem clients to the object stores, and a URL for each filesystem for its testing.</p>

<ol style="list-style-type: decimal">
  
<li><tt>test.fs.s3n.name</tt> : the URL of the bucket for S3n tests</li>
  
<li><tt>test.fs.s3a.name</tt> : the URL of the bucket for S3a tests</li>
  
<li><tt>test.fs.s3.name</tt> : the URL of the bucket for &#x201c;S3&#x201d; tests</li>
</ol>
<p>The contents of each bucket will be destroyed during the test process: do not use the bucket for any purpose other than testing. Furthermore, for s3a, all in-progress multi-part uploads to the bucket will be aborted at the start of a test (by forcing <tt>fs.s3a.multipart.purge=true</tt>) to clean up the temporary state of previously failed tests.</p>
<p>Example:</p>

<div class="source">
<div class="source">
<pre>&lt;configuration&gt;

  &lt;property&gt;
    &lt;name&gt;test.fs.s3n.name&lt;/name&gt;
    &lt;value&gt;s3n://test-aws-s3n/&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;test.fs.s3a.name&lt;/name&gt;
    &lt;value&gt;s3a://test-aws-s3a/&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;test.fs.s3.name&lt;/name&gt;
    &lt;value&gt;s3://test-aws-s3/&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;fs.s3.awsAccessKeyId&lt;/name&gt;
    &lt;value&gt;DONOTPCOMMITTHISKEYTOSCM&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;fs.s3.awsSecretAccessKey&lt;/name&gt;
    &lt;value&gt;DONOTEVERSHARETHISSECRETKEY!&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;fs.s3n.awsAccessKeyId&lt;/name&gt;
    &lt;value&gt;DONOTPCOMMITTHISKEYTOSCM&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;fs.s3n.awsSecretAccessKey&lt;/name&gt;
    &lt;value&gt;DONOTEVERSHARETHISSECRETKEY!&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;fs.s3a.access.key&lt;/name&gt;
    &lt;description&gt;AWS access key ID. Omit for Role-based authentication.&lt;/description&gt;
    &lt;value&gt;DONOTCOMMITTHISKEYTOSCM&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;fs.s3a.secret.key&lt;/name&gt;
    &lt;description&gt;AWS secret key. Omit for Role-based authentication.&lt;/description&gt;
    &lt;value&gt;DONOTEVERSHARETHISSECRETKEY!&lt;/value&gt;
  &lt;/property&gt;
&lt;/configuration&gt;
</pre></div></div></div></div>
<div class="section">
<h2><a name="File_contract-test-options.xml"></a>File <tt>contract-test-options.xml</tt></h2>
<p>The file <tt>hadoop-tools/hadoop-aws/src/test/resources/contract-test-options.xml</tt> must be created and configured for the test filesystems.</p>
<p>If a specific file <tt>fs.contract.test.fs.*</tt> test path is not defined for any of the filesystems, those tests will be skipped.</p>
<p>The standard S3 authentication details must also be provided. This can be through copy-and-paste of the <tt>auth-keys.xml</tt> credentials, or it can be through direct XInclude inclusion.</p>
<div class="section">
<div class="section">
<h4><a name="s3:"></a>s3://</h4>
<p>The filesystem name must be defined in the property <tt>fs.contract.test.fs.s3</tt>. </p>
<p>Example:</p>

<div class="source">
<div class="source">
<pre>  &lt;property&gt;
    &lt;name&gt;fs.contract.test.fs.s3&lt;/name&gt;
    &lt;value&gt;s3://test-aws-s3/&lt;/value&gt;
  &lt;/property&gt;
</pre></div></div></div></div>
<div class="section">
<h3><a name="s3n:"></a>s3n://</h3>
<p>In the file <tt>src/test/resources/contract-test-options.xml</tt>, the filesystem name must be defined in the property <tt>fs.contract.test.fs.s3n</tt>. The standard configuration options to define the S3N authentication details must also be provided.</p>
<p>Example:</p>

<div class="source">
<div class="source">
<pre>  &lt;property&gt;
    &lt;name&gt;fs.contract.test.fs.s3n&lt;/name&gt;
    &lt;value&gt;s3n://test-aws-s3n/&lt;/value&gt;
  &lt;/property&gt;
</pre></div></div></div>
<div class="section">
<h3><a name="s3a:"></a>s3a://</h3>
<p>In the file <tt>src/test/resources/contract-test-options.xml</tt>, the filesystem name must be defined in the property <tt>fs.contract.test.fs.s3a</tt>. The standard configuration options to define the S3N authentication details must also be provided.</p>
<p>Example:</p>

<div class="source">
<div class="source">
<pre>&lt;property&gt;
  &lt;name&gt;fs.contract.test.fs.s3a&lt;/name&gt;
  &lt;value&gt;s3a://test-aws-s3a/&lt;/value&gt;
&lt;/property&gt;
</pre></div></div></div>
<div class="section">
<h3><a name="Complete_example_of_contract-test-options.xml"></a>Complete example of <tt>contract-test-options.xml</tt></h3>

<div class="source">
<div class="source">
<pre>&lt;?xml version=&quot;1.0&quot;?&gt;
&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;
&lt;!--
  ~ Licensed to the Apache Software Foundation (ASF) under one
  ~  or more contributor license agreements.  See the NOTICE file
  ~  distributed with this work for additional information
  ~  regarding copyright ownership.  The ASF licenses this file
  ~  to you under the Apache License, Version 2.0 (the
  ~  &quot;License&quot;); you may not use this file except in compliance
  ~  with the License.  You may obtain a copy of the License at
  ~
  ~       http://www.apache.org/licenses/LICENSE-2.0
  ~
  ~  Unless required by applicable law or agreed to in writing, software
  ~  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  ~  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  ~  See the License for the specific language governing permissions and
  ~  limitations under the License.
  --&gt;

&lt;configuration&gt;

  &lt;include xmlns=&quot;http://www.w3.org/2001/XInclude&quot;
    href=&quot;auth-keys.xml&quot;/&gt;

  &lt;property&gt;
    &lt;name&gt;fs.contract.test.fs.s3&lt;/name&gt;
    &lt;value&gt;s3://test-aws-s3/&lt;/value&gt;
  &lt;/property&gt;


  &lt;property&gt;
    &lt;name&gt;fs.contract.test.fs.s3a&lt;/name&gt;
    &lt;value&gt;s3a://test-aws-s3a/&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;fs.contract.test.fs.s3n&lt;/name&gt;
    &lt;value&gt;s3n://test-aws-s3n/&lt;/value&gt;
  &lt;/property&gt;

&lt;/configuration&gt;
</pre></div></div>
<p>This example pulls in the <tt>auth-keys.xml</tt> file for the credentials. This provides one single place to keep the keys up to date &#x2014;and means that the file <tt>contract-test-options.xml</tt> does not contain any secret credentials itself.</p></div></div>
      </div>
    </div>
    <div class="clear">
      <hr/>
    </div>
    <div id="footer">
      <div class="xright">&#169;            2016
              Apache Software Foundation
            
                       - <a href="http://maven.apache.org/privacy-policy.html">Privacy Policy</a></div>
      <div class="clear">
        <hr/>
      </div>
    </div>
  </body>
</html>
